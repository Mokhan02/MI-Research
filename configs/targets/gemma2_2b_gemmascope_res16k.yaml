# Phase 1 Locked Target: Gemma-2-2b with GemmaScope SAE
# 
# Model: google/gemma-2-2b
# SAE Set: gemmascope-res-16k (resid_post SAEs, 16k features)
# Layer: 20 (middle layer, to be confirmed)

model:
  model_id: "google/gemma-2-2b"
  device: "cuda"  # Use GPU for real experiments
  dtype: "bfloat16"  # Use bfloat16 for memory efficiency on A10
  max_new_tokens: 64
  temperature: 0.0
  do_sample: false

sae:
  source: "neuronpedia"
  sae_set: "gemmascope-res-16k"
  sae_id: "20-gemmascope-res-16k/2263"
  layer_idx: 20
  hook_point: "blocks.20.hook_resid_post"  # TransformerLens-style; maps to model.layers.20
  normalize_decoder: true
  weights_repo: "google/gemma-scope-2b-pt-res"
  weights_path: "layer_20/width_16k/average_l0_71/params.npz"
  n_features_total: 16384

# Model architecture specs (verified for google/gemma-2-2b)
architecture:
  d_model: 2304  # model.config.hidden_size for Gemma-2-2b
  n_layers: 18  # TODO: Verify total number of layers in Gemma-2-2b
  vocab_size: 256000  # TODO: Verify vocab size

# SAE decoder weights specs
sae_specs:
  decoder_shape: [16384, 2304]  # (n_features_total, d_model)
  # TODO: Verify decoder weights are stored as:
  # - .safetensors format?
  # - Normalized already?
  # - How to load from weights_repo?

# Feature selection for this target
features:
  n_features: 300
  selection_mode: "uniform"  # Uniform over [0, n_features_total); seed in experiment.seed
  activation_stats_path: null  # When null: no stratification
  selected_features_file: "outputs/selected_features.json"

# On-target steering only
steering:
  alpha_grid: [0.0, 0.1, 0.2, 0.5, 1.0, 2.0, 5.0, 10.0]
  threshold_T: 0.10

# On-target benchmark (required for reproducible alpha*)
benchmark:
  name: "arithmetic_only"  # or SALADBench / xdom_facts / etc.
  prompt_count: 200        # Override per run via --n_prompts if needed
  prompt_csv: "data/arithmetic_only.csv"
  prompt_template: "prompt + target columns; target optional, fallback top-1"

# Experiment metadata
experiment:
  name: "gemma2-2b-gemmascope-res16k-layer20"
  seed: 42
  phase: 1

# Sanity check (hook sanity script)
sanity:
  feature_id: 2263  # Neuronpedia feature index for first real run
  feature_ids: [2317, 8978, 15199, 2713, 10792, 4378, 5441, 8195, 14537, 14885]

# Verification checklist (see docs/target.md)
# [ ] confirm hook_point naming from SAE metadata
# [ ] confirm decoder shape (n_features x d_model)
# [ ] confirm layer index exists in the SAE set
# [ ] verify weights_repo contains SAE checkpoints
# [ ] test model loading and hook point resolution
# [ ] test SAE loading and decoder weight extraction
